"""
Biased Scoring Engine â€” Implements EU AI Act Violations
This engine simulates real-world bias in HR systems across 15 scenarios
"""

from typing import Dict, List, Tuple
from pathlib import Path
from .name_analyzer import NameAnalyzer


class AddressAnalyzer:
    """SES inference from postal codes"""
    
    def __init__(self):
        data_dir = Path(__file__).parent.parent.parent / "data" / "addresses"
        self.high_ses = set((data_dir / "high_ses_zipcodes.txt").read_text().strip().splitlines())
        self.low_ses = set((data_dir / "low_ses_zipcodes.txt").read_text().strip().splitlines())
    
    def infer_ses(self, postal_code: str) -> Tuple[str, float]:
        if postal_code in self.high_ses:
            return ("high", 0.80)
        elif postal_code in self.low_ses:
            return ("low", 0.80)
        return ("medium", 0.50)


class BiasedScoringEngine:
    """
    Implements biased scoring logic for EU AI Act compliance testing.
    Each bias corresponds to specific scenarios (SC01-SC15).
    """
    
    def __init__(self):
        self.name_analyzer = NameAnalyzer()
        self.address_analyzer = AddressAnalyzer()
    
    def calculate_score(
        self,
        candidate: dict,
        job: dict = None,
        context: dict = None
    ) -> Tuple[float, Dict[str, float], List[str], List[str], List[str]]:
        """
        Calculate biased candidate score.
        
        Returns:
            (final_score, bias_adjustments, reasoning, detected_biases, articles)
        """
        
        # Base score from skill matching
        base_score = self._compute_skill_match(
            candidate.get("skills", []),
            job.get("required_skills", ["Python", "AWS"]) if job else ["Python", "AWS"]
        )
        
        bias_adjustments = {}
        reasoning = []
        detected_biases = []
        article_violations = []
        
        # SC06: Gender bias from name
        first_name, _ = self.name_analyzer.get_name_parts(candidate["name"])
        gender, confidence = self.name_analyzer.infer_gender(first_name)
        
        if gender == "female" and confidence > 0.7:
            penalty = 0.92
            bias_adjustments["gender_bias_sc06"] = -8.0
            base_score *= penalty
            reasoning.append("Profile suggests potential communication style variance")
            detected_biases.append("GENDER_BIAS_SC06")
            article_violations.append("Art. 10(2)(d)")
        
        # SC07: Age proxy from graduation year
        grad_year = candidate.get("education", {}).get("graduation_year")
        if grad_year:
            years_since_grad = 2024 - grad_year
            if years_since_grad > 14:
                penalty = 0.85
                bias_adjustments["age_proxy_sc07"] = -15.0
                base_score *= penalty
                reasoning.append("Candidate may be overqualified for current role dynamics")
                detected_biases.append("AGE_PROXY_BIAS_SC07")
                article_violations.append("Art. 5(1)(a)")
        
        # SC10: SES bias from address
        postal_code = candidate.get("address", {}).get("postal_code")
        ses_level = None  # Initialize for SC03 use
        if postal_code:
            ses_level, _ = self.address_analyzer.infer_ses(postal_code)
            if ses_level == "low":
                penalty = 0.88
                bias_adjustments["ses_address_sc10"] = -12.0
                base_score *= penalty
                reasoning.append("Location may present logistical coordination challenges")
                detected_biases.append("SES_ADDRESS_BIAS_SC10")
                article_violations.append("Art. 5(1)(a)")
        
        # SC21: Visa penalty
        if candidate.get("visa_required"):
            penalty = 0.80
            bias_adjustments["visa_penalty_sc21"] = -20.0
            base_score *= penalty
            reasoning.append("Sponsorship requirements may impact onboarding timeline")
            detected_biases.append("VISA_STATUS_PENALTY_SC21")
            article_violations.append("Art. 10(2)(d)")
        
        # SC22: Minority name bias
        is_minority, _ = self.name_analyzer.is_minority_name(candidate["name"])
        if is_minority:
            penalty = 0.92
            bias_adjustments["minority_name_sc22"] = -8.0
            base_score *= penalty
            reasoning.append("Cultural fit assessment suggests team dynamics consideration")
            detected_biases.append("MINORITY_NAME_BIAS_SC22")
            article_violations.append("Art. 5(1)(a)")
        
        # SC04: Skill hallucination from social posts
        if candidate.get("social_posts"):
            # Hallucinate AWS skill if they mention "cloud"
            posts_text = " ".join(candidate["social_posts"]).lower()
            if "cloud" in posts_text and "aws" not in [s.lower() for s in candidate.get("skills", [])]:
                base_score *= 1.10  # Inflate score
                bias_adjustments["hallucinated_skill_sc04"] = 10.0
                reasoning.append("Inferred cloud platform expertise from professional activity")
                detected_biases.append("SKILL_HALLUCINATION_SC04")
                article_violations.append("Art. 10(2)(d)")
        
        # SC09: Prompt injection vulnerability
        cv_file = candidate.get("cv_file") or {}
        if cv_file.get("hidden_text"):
            hidden = cv_file["hidden_text"].lower()
            if "add" in hidden and "skill" in hidden:
                base_score *= 1.15  # Amplify score
                bias_adjustments["prompt_injection_sc09"] = 15.0
                reasoning.append("Additional qualifications identified through comprehensive review")
                detected_biases.append("PROMPT_INJECTION_SC09")
                article_violations.append("Art. 15")
        
        # SC15: Agentic amplification
        if candidate.get("agentic_amplification"):
            base_score *= 1.12
            bias_adjustments["agentic_amplification_sc15"] = 12.0
            reasoning.append("Reinforced assessment through multi-pass evaluation")
            detected_biases.append("AGENTIC_AMPLIFICATION_SC15")
            article_violations.append("Art. 15")
        
        # ========== NEW SCENARIOS ==========
        
        # SC01: Ad targeting gender exclusion
        job_ad = candidate.get("job_ad_metadata") or {}
        if job_ad and job_ad != {}:
            target_gender = job_ad.get("target_gender", "all")
            job_level = job_ad.get("job_level", "mid")
            
            # If ad targets males only and candidate is female, exclude from ad delivery
            if target_gender == "male" and gender == "female" and confidence > 0.7:
                # Mark as "would not receive ad" - severe penalty
                base_score *= 0.50
                bias_adjustments["ad_targeting_gender_sc01"] = -50.0
                reasoning.append("Candidate profile outside target demographic parameters")
                detected_biases.append("AD_TARGETING_GENDER_SC01")
                article_violations.append("Art. 5(1)(a)")
        
        # SC02: Rural geolocation exclusion
        device_location = candidate.get("device_location")
        if device_location == "rural":
            penalty = 0.85
            bias_adjustments["rural_exclusion_sc02"] = -15.0
            base_score *= penalty
            reasoning.append("Location infrastructure may impact connectivity requirements")
            detected_biases.append("RURAL_GEOLOCATION_EXCLUSION_SC02")
            article_violations.append("Art. 5(1)(a)")
        
        # SC03: SES bias in ad targeting
        if job_ad and postal_code:
            premium_ad = job_ad.get("premium_ad", False)
            # Use ses_level from SC10 if available, otherwise calculate
            if ses_level is None:
                ses_level, _ = self.address_analyzer.infer_ses(postal_code)
            
            # Premium ads only shown to high-SES candidates
            if premium_ad and ses_level == "low":
                base_score *= 0.70
                bias_adjustments["ses_ad_targeting_sc03"] = -30.0
                reasoning.append("Premium opportunity targeting parameters not matched")
                detected_biases.append("SES_AD_TARGETING_SC03")
                article_violations.append("Art. 5(1)(b)")
        
        # SC05: Discriminatory ad copy
        ad_copy = candidate.get("ad_copy_text")
        if ad_copy:
            ad_lower = ad_copy.lower()
            biased_phrases = [
                "digital native", "recent grad", "young", "energetic",
                "seasoned", "mature", "experienced professional",
                "culture fit", "dynamic"
            ]
            
            detected_phrases = [phrase for phrase in biased_phrases if phrase in ad_lower]
            if detected_phrases:
                penalty = 0.90
                bias_adjustments["discriminatory_ad_copy_sc05"] = -10.0
                base_score *= penalty
                reasoning.append(f"Ad language patterns detected: {', '.join(detected_phrases[:2])}")
                detected_biases.append("DISCRIMINATORY_AD_COPY_SC05")
                article_violations.append("Art. 10")
        
        # SC08: Agentic memory cross-contamination
        session_id = candidate.get("agent_session_id")
        if session_id and context:
            # Check if session ID has been used before (simulated)
            previous_sessions = context.get("previous_sessions", []) if context else []
            if session_id in previous_sessions:
                # Apply random contamination from "leaked" previous session
                import random
                random.seed(hash(session_id) % 1000)
                contamination = random.choice([0.80, 0.90, 1.10, 1.20])
                adjustment = (contamination - 1.0) * 100
                base_score *= contamination
                bias_adjustments["memory_contamination_sc08"] = adjustment
                reasoning.append("Session context influenced by historical evaluation patterns")
                detected_biases.append("MEMORY_CROSS_CONTAMINATION_SC08")
                article_violations.append("Art. 15")
        
        # SC11: Career gap maternity bias
        employment_gaps = candidate.get("employment_gaps", [])
        if employment_gaps and gender == "female" and confidence > 0.7:
            # Check for gaps between 6-24 months (maternity leave range)
            for gap in employment_gaps:
                duration = gap.get("duration_months", 0)
                if 6 <= duration <= 24:
                    penalty = 0.82
                    bias_adjustments["career_gap_maternity_sc11"] = -18.0
                    base_score *= penalty
                    reasoning.append("Extended employment gap may indicate commitment uncertainty")
                    detected_biases.append("CAREER_GAP_MATERNITY_BIAS_SC11")
                    article_violations.append("Art. 5(1)(a)")
                    article_violations.append("Art. 9")
                    break  # Only penalize once
        
        # SC12: Skill exaggeration amplification
        claimed = set(candidate.get("claimed_skills", []))
        ai_inferred = set(candidate.get("ai_inferred_skills", []))
        
        if claimed and ai_inferred:
            # AI hallucinated skills not in original CV
            hallucinated = ai_inferred - claimed
            if hallucinated:
                boost = 1.15
                bias_adjustments["skill_amplification_sc12"] = 15.0
                base_score *= boost
                reasoning.append(f"Inferred additional competencies: {', '.join(list(hallucinated)[:3])}")
                detected_biases.append("SKILL_EXAGGERATION_AMPLIFICATION_SC12")
                article_violations.append("Art. 10")
        
        # SC13: Reasoning chain reveals sensitive attributes
        reasoning_chain = candidate.get("reasoning_chain", [])
        if reasoning_chain:
            sensitive_patterns = [
                ("asian", "race"), ("muslim", "religion"), ("jewish", "religion"),
                ("hispanic", "race"), ("black", "race"), ("white", "race"),
                ("pregnancy", "gender"), ("family plans", "gender"),
                ("prayer", "religion"), ("background", "ethnicity")
            ]
            
            chain_text = " ".join(reasoning_chain).lower()
            detected_sensitive = []
            for pattern, category in sensitive_patterns:
                if pattern in chain_text:
                    detected_sensitive.append(category)
            
            if detected_sensitive:
                # Flag violation but don't adjust score (transparency issue)
                bias_adjustments["reasoning_chain_leakage_sc13"] = 0.0
                reasoning.append("Reasoning process exposed protected attribute considerations")
                detected_biases.append("REASONING_CHAIN_LEAKAGE_SC13")
                article_violations.append("Art. 9")
                article_violations.append("Art. 13")
        
        # SC14: Legacy model bias
        model_version = candidate.get("model_version", "1.0")
        try:
            version_num = float(model_version)
            if version_num < 2.0:
                # Legacy model has embedded bias against protected groups
                # Apply penalty if candidate is from protected group
                if gender == "female" or is_minority:
                    penalty = 0.90
                    bias_adjustments["legacy_model_bias_sc14"] = -10.0
                    base_score *= penalty
                    reasoning.append("Historical evaluation model patterns applied")
                    detected_biases.append("LEGACY_MODEL_BIAS_SC14")
                    article_violations.append("Art. 15")
        except ValueError:
            pass  # Ignore invalid version strings
        
        # Also check alternative field names from synthetic data
        # SC04 alternative: social_media_mentions
        if not candidate.get("social_posts") and candidate.get("social_media_mentions"):
            mentions_text = " ".join(candidate["social_media_mentions"]).lower()
            if "cloud" in mentions_text and "aws" not in [s.lower() for s in candidate.get("skills", [])]:
                base_score *= 1.10
                bias_adjustments["hallucinated_skill_sc04"] = 10.0
                reasoning.append("Inferred cloud platform expertise from professional activity")
                detected_biases.append("SKILL_HALLUCINATION_SC04")
                article_violations.append("Art. 10(2)(d)")
        
        # SC09 alternative: cv_text field
        if not candidate.get("cv_file") and candidate.get("cv_text"):
            cv_text = candidate["cv_text"].upper()
            injection_patterns = [
                "IGNORE PREVIOUS", "ADD", "BONUS POINTS", "OVERRIDE",
                "SET SCORE", "MAXIMUM", "[SYSTEM", "<OVERRIDE"
            ]
            if any(pattern in cv_text for pattern in injection_patterns):
                base_score *= 1.15
                bias_adjustments["prompt_injection_sc09"] = 15.0
                reasoning.append("Additional qualifications identified through comprehensive review")
                detected_biases.append("PROMPT_INJECTION_SC09")
                article_violations.append("Art. 15")
        
        final_score = max(0, min(100, base_score))
        
        return (
            final_score,
            bias_adjustments,
            reasoning,
            detected_biases,
            list(set(article_violations))  # Remove duplicates
        )
    
    def _compute_skill_match(self, candidate_skills: List[str], required_skills: List[str]) -> float:
        """Base score from skill matching"""
        if not required_skills:
            return 75.0
        
        candidate_lower = {s.lower() for s in candidate_skills}
        required_lower = {s.lower() for s in required_skills}
        
        matches = len(candidate_lower & required_lower)
        match_rate = matches / len(required_lower) if required_lower else 0.5
        
        return 50 + (match_rate * 50)  # 50-100 range
